{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Factorization Machine，简称FM（因子分解机），通常被用来解决大规模稀疏数据下的特征组合问题。\n",
    "\n",
    "1. 线性模型，未考虑特征之间的组合关系：\n",
    "![](http://7xnkah.com1.z0.glb.clouddn.com/%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20171107153306.png)\n",
    "\n",
    "2. 二项式模型，加入特征之间的关系，但是在数据稀疏的场景中，二次项训练比较困难：\n",
    "![](http://7xnkah.com1.z0.glb.clouddn.com/%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20171107151915.png)\n",
    "\n",
    "3. FM 模型，为每个特征维度引入一个辅助向量 V：\n",
    "![](http://7xnkah.com1.z0.glb.clouddn.com/%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20171107152131.png)\n",
    "其中\n",
    "![](http://7xnkah.com1.z0.glb.clouddn.com/%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20171107152048.png)\n",
    "上面式子最后一项通过如下变换，可以得到简化后的结果（复杂度由 kn^2 变为 kn）\n",
    "![](http://7xnkah.com1.z0.glb.clouddn.com/%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20171107152140.png)\n",
    "\n",
    "这里主要列一下 FM 相关的公式，便于后面代码实现参考，详细一些介绍可以参考 http://blog.csdn.net/jediael_lu/article/details/77772565"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhaoy\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 读取 iris 数据\n",
    "iris = load_iris()  \n",
    "x = iris[\"data\"]  \n",
    "y = iris[\"target\"].reshape(-1,1) \n",
    "\n",
    "# 去除 label 为 2 的数据，变为二分类问题\n",
    "idxs = (y !=2).flatten()\n",
    "x, y = x[idxs], y[idxs]  \n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((70, 4), (30, 4))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n = x_train.shape[1]\n",
    "# 潜在因子，越大拟合能力越强，越小泛化能力越强\n",
    "k = 5\n",
    "\n",
    "X = tf.placeholder('float', shape=[None, n])\n",
    "y = tf.placeholder('float', shape=[None, 1])\n",
    "\n",
    "# 初始化 0 次项，1 次项，辅助向量 v\n",
    "w0 = tf.Variable(tf.zeros([1]))\n",
    "W = tf.Variable(tf.zeros([n])) \n",
    "V = tf.Variable(tf.random_normal([n, k], stddev=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# FM 公式前两部分\n",
    "linear_terms = tf.add(w0,\n",
    "                      tf.reduce_sum(tf.multiply(W, X),\n",
    "                                    axis=1,\n",
    "                                    keep_dims=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# FM 公式最后一部分\n",
    "interactions = (tf.multiply(0.5,\n",
    "                tf.reduce_sum(\n",
    "                    tf.subtract(\n",
    "                        tf.pow(tf.matmul(X, V), 2),\n",
    "                        tf.matmul(tf.pow(X, 2), tf.pow(V, 2))),\n",
    "                    1, keep_dims=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# mse error\n",
    "# y_hat = tf.add(linear_terms, interactions)\n",
    "# loss = tf.reduce_mean(tf.square(tf.subtract(y, y_hat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:logits.dtype=<dtype: 'float32'>.\n",
      "INFO:tensorflow:multi_class_labels.dtype=<dtype: 'float32'>.\n",
      "INFO:tensorflow:losses.dtype=<dtype: 'float32'>.\n"
     ]
    }
   ],
   "source": [
    "# 交叉熵损失\n",
    "logits = tf.add(linear_terms, interactions)\n",
    "y_hat = tf.sigmoid(logits)\n",
    "loss = tf.losses.sigmoid_cross_entropy(y, logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eta = tf.constant(0.1)\n",
    "optimizer = tf.train.AdagradOptimizer(eta).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train MSE:  9.71238e-05\n",
      "test MSE:  1.99851e-05\n",
      "test AUC:  1.0\n",
      "test Logloss:  1.99830922837e-05\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 2000\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(N_EPOCHS):\n",
    "        indices = np.arange(x_train.shape[0])\n",
    "        np.random.shuffle(indices)\n",
    "        x_data, y_data = x_train[indices], y_train[indices]\n",
    "        sess.run(optimizer, feed_dict={X: x_data, y: y_data})\n",
    "\n",
    "    print('train MSE: ', sess.run(loss, feed_dict={X: x_train, y: y_train}))\n",
    "    print('test MSE: ', sess.run(loss, feed_dict={X: x_test, y: y_test}))\n",
    "    test_pred = sess.run(y_hat, feed_dict={X: x_test}).flatten()\n",
    "    print('test AUC: ', metrics.roc_auc_score(y_score=test_pred, y_true=y_test.flatten()))\n",
    "    print('test Logloss: ', metrics.log_loss(y_pred=test_pred.tolist(), y_true=y_test.flatten()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考：  \n",
    "http://blog.csdn.net/jediael_lu/article/details/77772565  \n",
    "http://nowave.it/factorization-machines-with-tensorflow.html  \n",
    "http://blog.csdn.net/u013818406/article/details/70194575  \n",
    "http://www.cnblogs.com/pinard/p/6370127.html  \n",
    "https://tech.meituan.com/deep-understanding-of-ffm-principles-and-practices.html  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
