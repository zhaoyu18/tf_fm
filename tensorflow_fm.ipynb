{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scale_data(X, scaler=None):\n",
    "    if not scaler:\n",
    "        scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "        scaler.fit(X)\n",
    "    X = scaler.transform(X)\n",
    "    return X, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train and test data path\n",
    "DATA_TRAIN_PATH = '../kaggle/Porto Seguro/input/train.csv'\n",
    "DATA_TEST_PATH = '../kaggle/Porto Seguro/input/test.csv'\n",
    "\n",
    "def load_data(path_train=DATA_TRAIN_PATH, path_test=DATA_TEST_PATH):\n",
    "    train_loader = pd.read_csv(path_train, dtype={'target': np.int8, 'id': np.int32})\n",
    "    train = train_loader.drop(['target', 'id'], axis=1)\n",
    "    train_labels = train_loader['target'].values\n",
    "    train_ids = train_loader['id'].values\n",
    "    print('\\n Shape of raw train data:', train.shape)\n",
    "\n",
    "    test_loader = pd.read_csv(path_test, dtype={'id': np.int32})\n",
    "    test = test_loader.drop(['id'], axis=1)\n",
    "    test_ids = test_loader['id'].values\n",
    "    print(' Shape of raw test data:', test.shape)\n",
    "\n",
    "    return train, train_labels, test, train_ids, test_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Shape of raw train data: (595212, 57)\n",
      " Shape of raw test data: (892816, 57)\n",
      "\n",
      " Shape of processed train data: (595212, 207)\n",
      " Shape of processed test data: (892816, 207)\n"
     ]
    }
   ],
   "source": [
    "# Load data set and target values\n",
    "train, target, test, tr_ids, te_ids = load_data()\n",
    "n_train = train.shape[0]\n",
    "train_test = pd.concat((train, test)).reset_index(drop=True)\n",
    "\n",
    "calc_col = [c for c in train.columns if c.startswith('ps_calc_')]\n",
    "train_test.drop(calc_col, axis=1, inplace=True)\n",
    "\n",
    "col_to_drop = train.columns[train.columns.str.endswith('_cat')]\n",
    "col_to_dummify = train.columns[train.columns.str.endswith('_cat')].astype(str).tolist()\n",
    "\n",
    "dummy_df = pd.DataFrame()\n",
    "for col in col_to_dummify:\n",
    "    dummy = pd.get_dummies(train_test[col].astype('category'))\n",
    "    columns = dummy.columns.astype(str).tolist()\n",
    "    columns = [col + '_' + w for w in columns]\n",
    "    dummy.columns = columns\n",
    "    dummy_df = pd.concat((dummy_df, dummy), axis=1)\n",
    "\n",
    "train_test.drop(col_to_dummify, axis=1, inplace=True)\n",
    "train_test_scaled, scaler = scale_data(train_test)\n",
    "train_test_scaled = np.concatenate((train_test_scaled, dummy_df.values), axis=1)\n",
    "train = train_test_scaled[:n_train, :]\n",
    "test = train_test_scaled[n_train:, :]\n",
    "print('\\n Shape of processed train data:', train.shape)\n",
    "print(' Shape of processed test data:', test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhaoy\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(train, target, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((476169, 1), (119043, 1))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = y_train.reshape([-1, 1])\n",
    "y_test = y_test.reshape([-1, 1])\n",
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = x_train.shape[1]\n",
    "# 潜在因子，越大拟合能力越强，越小泛化能力越强\n",
    "k = 5\n",
    "\n",
    "X = tf.placeholder('float', shape=[None, n])\n",
    "y = tf.placeholder('float', shape=[None, 1])\n",
    "\n",
    "# 初始化 0 次项，1 次项，辅助向量 v\n",
    "w0 = tf.Variable(tf.zeros([1]))\n",
    "W = tf.Variable(tf.zeros([n])) \n",
    "V = tf.Variable(tf.random_normal([n, k], stddev=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# FM 公式前两部分\n",
    "linear_terms = tf.add(w0,\n",
    "                      tf.reduce_sum(tf.multiply(W, X),\n",
    "                                    axis=1,\n",
    "                                    keep_dims=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# FM 公式最后一部分\n",
    "interactions = (tf.multiply(0.5,\n",
    "                tf.reduce_sum(\n",
    "                    tf.subtract(\n",
    "                        tf.pow(tf.matmul(X, V), 2),\n",
    "                        tf.matmul(tf.pow(X, 2), tf.pow(V, 2))),\n",
    "                    1, keep_dims=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:logits.dtype=<dtype: 'float32'>.\n",
      "INFO:tensorflow:multi_class_labels.dtype=<dtype: 'float32'>.\n",
      "INFO:tensorflow:losses.dtype=<dtype: 'float32'>.\n"
     ]
    }
   ],
   "source": [
    "# 交叉熵损失\n",
    "logits = tf.add(linear_terms, interactions)\n",
    "y_hat = tf.sigmoid(logits)\n",
    "loss = tf.losses.sigmoid_cross_entropy(y, logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eta = tf.constant(0.1)\n",
    "optimizer = tf.train.AdagradOptimizer(eta).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.61497253798 0.152767066745\n",
      "0.619925546863 0.152460569993\n",
      "0.62241424577 0.152290122218\n",
      "0.623658351091 0.152175387746\n",
      "0.624337491699 0.152157207836\n",
      "0.624974966117 0.152070547131\n",
      "0.625337152741 0.152042165406\n",
      "0.626176870483 0.152091716624\n",
      "0.626216701893 0.15196906483\n",
      "0.627147227608 0.152018647046\n",
      "0.627178299586 0.151943730239\n",
      "0.628044657527 0.151862197424\n",
      "0.628587726185 0.151992469726\n",
      "0.628872430496 0.1518703834\n",
      "0.629698578951 0.151788684788\n",
      "0.629683070762 0.15175463274\n",
      "0.630598443113 0.151725005104\n",
      "0.630900222505 0.151687234047\n",
      "0.631441780881 0.151671391729\n",
      "0.630499608609 0.151723677746\n",
      "0.63211700527 0.151612973733\n",
      "0.632255106093 0.151618560218\n",
      "0.631933031909 0.151650318449\n",
      "0.631990671302 0.151610818767\n",
      "0.631868721599 0.151637860595\n",
      "0.632615971473 0.151592232138\n",
      "0.632765787595 0.151618607445\n",
      "0.632778620948 0.151690168359\n",
      "0.633337058291 0.151544171588\n",
      "0.633596543725 0.151549666885\n",
      "0.633819724772 0.151565636867\n",
      "0.633212179005 0.151560510785\n",
      "0.633856271774 0.15154803358\n",
      "0.634149020812 0.151509385109\n",
      "0.634300645431 0.151549693381\n",
      "0.634083116316 0.151573508892\n",
      "0.63388619436 0.151505522319\n",
      "0.634472443534 0.151477728759\n",
      "0.634631464895 0.151472432011\n",
      "0.635154710851 0.151450470032\n",
      "0.634762003189 0.151467699303\n",
      "0.635169680231 0.151447014459\n",
      "0.635277201384 0.15143270331\n",
      "0.634744962478 0.151555248136\n",
      "0.635655283371 0.151409151491\n",
      "0.635519195246 0.151411533112\n",
      "0.635394875998 0.151429288169\n",
      "0.635375950973 0.151427099163\n",
      "0.635518564446 0.151426237554\n",
      "0.635852613729 0.151404832495\n",
      "0.634833786058 0.151449537139\n",
      "0.635838008272 0.15138649918\n",
      "0.635095991819 0.151454320163\n",
      "0.636028399826 0.151391424898\n",
      "0.636112330659 0.151403463663\n",
      "0.635857741005 0.151422883622\n",
      "0.63613802668 0.151403208754\n",
      "0.636131242542 0.151373147406\n",
      "0.636026697473 0.151368921803\n",
      "0.635680788332 0.151412871303\n",
      "0.636070900007 0.151409050075\n",
      "0.635332682509 0.151496078577\n",
      "0.635698646859 0.151423212116\n",
      "0.635784433701 0.151417466681\n",
      "0.635966990794 0.151382579479\n",
      "0.635975408543 0.151396015479\n",
      "0.635974494691 0.151381851221\n",
      "0.63613233229 0.151396716619\n",
      "0.636101598964 0.151376067368\n",
      "0.635436531069 0.151428623083\n",
      "0.635948061725 0.151380650607\n",
      "0.635756510672 0.151458288283\n",
      "0.635829056769 0.15139728086\n",
      "0.635299701956 0.151428663075\n",
      "0.635275684026 0.151438990453\n",
      "0.635368155937 0.151458667417\n",
      "0.635936651717 0.151417794337\n",
      "0.635786039008 0.151400513326\n",
      "0.635823591853 0.151394552556\n",
      "0.636056331954 0.151383801061\n",
      "0.635128988546 0.151459178718\n",
      "0.635622742558 0.151406109521\n",
      "0.635703427397 0.151412240032\n",
      "0.635874863598 0.151429877622\n",
      "0.635368981841 0.151414283214\n",
      "0.635628898928 0.151434012379\n",
      "0.635885535651 0.151428189301\n",
      "0.635388070632 0.151439666155\n",
      "0.634957810124 0.151567824772\n",
      "0.635684773293 0.151451910076\n",
      "0.635492281093 0.151440598709\n",
      "0.635403271508 0.151418700097\n",
      "0.635560624886 0.151432270279\n",
      "0.635816608569 0.151398871113\n",
      "0.635472281483 0.151401703782\n",
      "0.635720935143 0.15140878801\n",
      "0.635967180843 0.151378778987\n",
      "0.635433344718 0.151479708334\n",
      "0.63569693642 0.15141271923\n",
      "0.635787203562 0.151423328559\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 100\n",
    "batch_size = 2048\n",
    "num_steps = x_train.shape[0] // batch_size + 1\n",
    "batch_size, num_steps\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(N_EPOCHS):\n",
    "        indices = np.arange(x_train.shape[0])\n",
    "        np.random.shuffle(indices)\n",
    "        x_train, y_train = x_train[indices], y_train[indices]\n",
    "        for step in range(num_steps):\n",
    "            offset = (step * batch_size) % (x_train.shape[0] - batch_size)\n",
    "            x_batch = x_train[offset:(offset + batch_size), :]\n",
    "            y_batch = y_train[offset:(offset + batch_size), :]\n",
    "            sess.run(optimizer, feed_dict={X: x_batch, y: y_batch})\n",
    "        test_pred = sess.run(y_hat, feed_dict={X: x_test}).flatten()\n",
    "        auc = metrics.roc_auc_score(y_score=test_pred, y_true=y_test.flatten())\n",
    "        logloss = metrics.log_loss(y_pred=test_pred.tolist(), y_true=y_test.flatten().tolist())\n",
    "        print(auc, logloss)\n",
    "#     print('train MSE: ', sess.run(loss, feed_dict={X: x_train, y: y_train}))\n",
    "#     print('test MSE: ', sess.run(loss, feed_dict={X: x_test, y: y_test}))\n",
    "#     test_pred = sess.run(y_hat, feed_dict={X: x_test}).flatten()\n",
    "#     print('test AUC: ', metrics.roc_auc_score(y_score=test_pred, y_true=y_test.flatten()))\n",
    "#     print('test Logloss: ', metrics.log_loss(y_pred=test_pred.tolist(), y_true=y_test.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27227605335999994"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.63613802668 * 2 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
